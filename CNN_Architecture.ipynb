{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbWVmuRlw3gd4chqu/lUDg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsaha28/EE954_ASSIGNMENT_GR21/blob/Bharti_S/CNN_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation"
      ],
      "metadata": {
        "id": "7kCbEFYE_YHL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN architecture consists of 5 convolutional layers followed by batch normalization, activation functions, and pooling layers\n",
        "\n",
        "First Convolutional Block:\n",
        "\n",
        "Convolutional layer with 1 input channel, 16 output channels, a 3x3 kernel size, and padding of 1. Batch normalization on 16 feature maps to stabilize and accelerate training. Activation function to introduce non-linearity. Downsamples the feature map by a factor of 2.\n",
        "\n",
        "Second Convolutional Block:\n",
        "\n",
        "This block starts with 16 input channels and outputs 32 channels, then follows with batch normalization, ReLU, and max pooling.\n",
        "\n",
        "Third Convolutional Block:\n",
        "\n",
        "Similarly, this block takes 32 input channels and outputs 64, with batch normalization, ReLU, and max pooling.\n",
        "\n",
        "Fourth Convolutional Block:\n",
        "\n",
        " This block has 64 input channels and 128 output channels, followed by batch normalization and ReLU activation but without max pooling.\n",
        "\n",
        "Fifth Convolutional Block:\n",
        "\n",
        "128 input channels are converted to 256 output channels, followed by batch normalization, ReLU, and max pooling."
      ],
      "metadata": {
        "id": "ZN1c3yKPAJ5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    class CustomConvModel(nn.Module):\n",
        "     def __init__(self):\n",
        "       super(CustomModel.CustomConvModel, self).__init__()\n",
        "       self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "     def forward(self, x):\n",
        "            x = self.conv_layer(x)\n",
        "            return x"
      ],
      "metadata": {
        "id": "56kxOzox_gdX"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}