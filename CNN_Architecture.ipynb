{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsaha28/EE954_ASSIGNMENT_GR21/blob/Bharti_S/CNN_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation"
      ],
      "metadata": {
        "id": "7kCbEFYE_YHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN architecture consists of 5 convolutional layers followed by batch normalization, activation functions, and pooling layers\n",
        "\n",
        "First Convolutional Block:\n",
        "\n",
        "Convolutional layer with 1 input channel, 16 output channels, a 3x3 kernel size, and padding of 1. Batch normalization on 16 feature maps to stabilize and accelerate training. Activation function to introduce non-linearity. Downsamples the feature map by a factor of 2.\n",
        "\n",
        "Second Convolutional Block:\n",
        "\n",
        "This block starts with 16 input channels and outputs 32 channels, then follows with batch normalization, ReLU, and max pooling.\n",
        "\n",
        "Third Convolutional Block:\n",
        "\n",
        "Similarly, this block takes 32 input channels and outputs 64, with batch normalization, ReLU, and max pooling.\n",
        "\n",
        "Fourth Convolutional Block:\n",
        "\n",
        " This block has 64 input channels and 128 output channels, followed by batch normalization and ReLU activation but without max pooling.\n",
        "\n",
        "Fifth Convolutional Block:\n",
        "\n",
        "128 input channels are converted to 256 output channels, followed by batch normalization, ReLU, and max pooling."
      ],
      "metadata": {
        "id": "ZN1c3yKPAJ5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "uWMXjfba4OaW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "     def __init__(self):\n",
        "       super(CustomModel, self).__init__()\n",
        "       self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "     def forward(self, x):\n",
        "            x = self.conv_layer(x)\n",
        "            return x"
      ],
      "metadata": {
        "id": "56kxOzox_gdX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a grayscale image of size 28x28, Create a sample input tensor with dimensions (batch_size, channels, height, width)."
      ],
      "metadata": {
        "id": "F5EyJgE-6Xmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomModel()\n",
        "# Create a sample input tensor with shape (1, 1, 28, 28)\n",
        "input_data = torch.randn(1, 1, 28, 28)\n",
        "# Pass the input through the model\n",
        "output = model(input_data)\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Output data:\", output)"
      ],
      "metadata": {
        "id": "ifWyUgSR41wo",
        "outputId": "c440c11e-d0a8-46a7-ba14-e3f468bcdbc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 256, 3, 3])\n",
            "Output data: tensor([[[[0.0000, 0.4546, 0.4467],\n",
            "          [0.0000, 2.2533, 0.5201],\n",
            "          [0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.6720],\n",
            "          [0.0000, 0.0000, 0.0000],\n",
            "          [0.8016, 0.0000, 2.1984]],\n",
            "\n",
            "         [[1.4889, 0.0000, 0.3624],\n",
            "          [0.0000, 1.1120, 0.0000],\n",
            "          [0.0000, 0.0000, 0.6325]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.1944, 0.2076, 0.4491],\n",
            "          [0.0000, 0.0000, 1.6183],\n",
            "          [0.0000, 0.0000, 0.1062]],\n",
            "\n",
            "         [[0.0000, 0.0000, 1.9431],\n",
            "          [0.0000, 0.0000, 0.2714],\n",
            "          [0.0000, 0.0000, 1.5690]],\n",
            "\n",
            "         [[0.0000, 0.1281, 0.0000],\n",
            "          [0.0408, 0.5190, 0.0000],\n",
            "          [0.6911, 0.0000, 1.7738]]]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    }
  ]
}